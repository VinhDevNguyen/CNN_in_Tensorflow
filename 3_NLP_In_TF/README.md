![](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2019/06/Website-TFSDesktopBanner.png)

### [Week 1: Sentiment In Text](./Week_1/)
* [ ] Slide
  * [ ] Word based encodings
  * [x] Tokenizer
  * [ ] Text to sequence
  * [ ] Looking more at the Tokenizer
  * [ ] Padding
  * [ ] Working with the Tokenizer on news healines dataset
 
### Week 2: Augmentation, a Technique to Avoid Overfitting
* [ ] Slide
  * [ ] Introduction
  * [ ] The IMDB dataset
  * [ ] Looking into the details
  * [ ] How can we use vectors?
  * [ ] More into the details
  * [ ] Remember the sarcasm dataset?
  * [ ] Building a classifier for the sarcasm dataset
  * [ ] Let's talk about the loss function
  * [ ] Pre-tokenized datasets
  * [ ] Diving into the code (part 1)
  * [ ] Diving into the code (part 2)

### Week 3: Sequence models

* [ ] Slide
  * [ ] Introduction
  * [ ] LSTMs
  * [ ] Implementing LSTMs in code
  * [ ] Accuracy and loss
  * [ ] Looking into the code
  * [ ] Using a convolutional network
  * [ ] Going back to the IMDB

### Week 4: Sequence models and literature

* [ ] Slide
  * [ ] Introduction
  * [ ] Looking into the code
  * [ ] Training the data
  * [ ] More on training the data
  * [ ] Finding what the next word should be
  * [ ] Predicting a word
  * [ ] Poetry!
  * [ ] Looking into the code