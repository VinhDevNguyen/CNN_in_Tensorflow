{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import tensorflow\n","from tensorflow.keras.preprocessing.text import Tokenizer\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["\nWord Index =  {'<OOV_tok>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n"]}],"source":["# Word based encoding\n","sentences = [\n","             'I love my dog',\n","             'I love my cat',\n","             'You love my dog!',\n","             'Do you think my dog is amazing'\n","]\n","\n","tokenizer = Tokenizer(num_words= 100, oov_token=\"<OOV_tok>\") # Using out of vocabulary token\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","print(\"\\nWord Index = \", word_index)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["\nTexts to sequences:\ni really love my dog  ->  [5, 1, 3, 2, 4]\nmy dog loves my manatee  ->  [2, 4, 1, 2, 1]\n"]}],"source":["# Text to sequence\n","test_data = [\n","    'i really love my dog',\n","    'my dog loves my manatee'\n","]\n","test_seq = tokenizer.texts_to_sequences(test_data)\n","print('\\nTexts to sequences:')\n","for i in range(len(test_data)):\n","    print(test_data[i], ' -> ', test_seq[i])\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}